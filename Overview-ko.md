# 맥락 기반 로깅 및 RAG 옵저버빌리티 시스템 (Context-Aware Logging & RAG Observability)

> 파편화된 텍스트 로그를 진실성을 잃지 않으면서 맥락을 자연어로 직접 검색할 수 있도록 구현한 프로젝트 입니다.

이 프로젝트는 전통적인 로깅 파이프라인을

- **맥락 기반(Context-aware)의 요청 단위 이벤트 로그(Wide-event)**
- **보안 우선(Security-first)**
- **RAG 기반 분석 플랫폼**으로 점진적으로 발전시키는 (Phase 1 ~ 5) 과정을 담은 로그 관측 시스템입니다.

단순히 디버깅을 위한 텍스트 로그를 남기는 것에 그치지 않고,
각 요청을 풍부한 맥락을 가진 **1급 이벤트(First-class Event, Wide Event/Canonical Log Line)**로 취급합니다.
이를 통해 신뢰성과 감사 가능성을 유지하면서도 분석 수준의 디버깅, 안전한 데이터 조회, 그리고 AI 지원 추론이 가능한 구조를 구현하고자 했습니다.

---

## 🚨 개발 동기 (Motivation)

1. 영감을 얻었던 게시글 내용

- [https://news.hada.io/topic?id=25239] GeekNews 게시글: '로깅은 엉망이다'
- 현대 분산 시스템에서 많은 경우 개별 서비스는 로그 데이터를 저장하는 방식 또한 개별 적이기에 (monolithic) 다중 서비스 / 캐시 및 데이터 저장소의 맥락을 파악하는게 어렵다는 내용에 주목하게 되었습니다.
- 특히 다음과 같은 부분에 많은 공감을 하게 되었습니다.
  - 개별 서비스의 로그데이터의 필드 형식은 다양할 수 있어 문자열 검색의 한계가 있다는 점
  - 로그 데이터 형식은 주로 쓰기 작업에 주안점을 두어 구성되기에 일관적인 쿼리 방식을 적용하는 것이 힘들다는 점

2. 1의 게시글에 관심을 가지게 된 배경

- 실무 경험:
  - 서비스 인스턴스 별로 독립된 로그를 남기는 경우
  - 동일한 요청/이벤트에서 파생된 로그들을 취합하는데 어려움이 많았었고
  - 문제 상황 발생시 즉각 적인 파악에 비효율을 체감했었습니다.
  - 즉, 맥락(Context)은 서비스, 데이터베이스, 캐시, 큐 사이에 파편화되어 흩어져 있어 데이터 간의 구조나 관계를 추론하는 것이 비효율적임을 직접 경험했습니다.

- 프로젝트 경험:
  - 웹 서비스 전반을 구성하는 경험을 하면서
  - 프론트엔드에서의 유저 활동 추적 / 백엔드에서의 요청 수행 로그 / 데이터베이스의 실행 내역을 각각 확인하는 것에 불편함을 느꼈습니다.
  - 개발 진행 과정 또한 더뎌질 수 밖에 없었고, 이 문제는 개발이 진행될 수록 더 부담이 되었습니다.

- 커뮤니티에서 확인한 공감대
  - MongoDB User Group Korea 세미나에 참석하여 다른 개발자분들로 부터 이와 같은 문제에 대한 공감대가 일부 있음을 확인했습니다.
    - 질문 예시 1: '서비스 별 로그 데이터를 분산된 컬렉션에 저장한다고 가정했을 때 어떻게 관리하는게 좋을까요?'
      -> 개별 로그데이터의 저장 컬렉션 또한 나누어져 관리되고 있다면, 일관된 규칙을 적용하고 관리하는데 리소스가 많이 소비될 것으로 예상했습니다.
    - 질문 예시 2: '현재 시스템에서 MongoDB 컬렉션에 로그데이터를 적재하는데, 조회 작업을 개선하려면 어떻게 해야 할까요?'
      -> 당장 떠올랐던 저의 의견은, 시계열 데이터등 로그 데이터라면 반드시 가지고 있을 법한 속성을 기준으로 조회 작업을 최적화 하는 것이었는데,
      로그 별로 저장하는 속성의 종류가 일관적이라고 기대하기는 힘들다는 생각 또한 떠올랐습니다.

3. 아이디어

- 추후에 커뮤니티에서 이루어진 3 회의 강의 세션 (MongoDB AI Skill Session: Vector Search / RAG / Agentic retrieval)에 참여하고 나서,
  앞서 설명한 Geek News의 내용을 접하게 되었고 다음과 같은 생각을 하게 되었습니다.
- Wide Event 형식으로 로그데이터를 남긴다면, 하나의 요청건과 관련한 이벤트, 처리결과 데이터 등으로 로그데이터를 구성되했다고 가정할 수 있고,
- 자체로 일관된 맥락을 가지고 있다고 볼 수 있으며
- 요청건에 대한 이벤트/ 처리결과 전반을 저장하기에 내용 또한 충분히 풍부할 수 있고, 이는 1 건의 맥락으로 간주하고 전처리하여 자연어 질의를 통해 검색할 수 있다는 것이 첫 아이디어 였습니다.
- 시스템 성능과 배포 단계 별 이력 등을 선제적으로 검색하고 경우에 따라 성능정보를 제공할 수 있으면, 제가 경험했던 비효율을 줄이는데 도움이 될 것이라고 가정하고 프로젝트를 구상했습니다.
- 따라서 2 가지 목적을 달성하는 것을 목표로 프로젝트 구현을 하고자 했습니다.
  - 하나의 요청건을 처리하는데 발생하는 이벤트 전반을 하나의 로그데이터로 남길 수 있을 것
  - 이 로그데이터에 대해 자연어 질의가 가능 할 것

4. 가정했던 주의점

- AI 기반 시스템(RAG)은 **데이터 유출, 환각(Hallucination), 신뢰 상실**이라는 새로운 리스크를 가져올 수 있다고 생각했습니다.
- 따라서 원본 로그데이터는 하나의 저장소에 순차적으로 저장만 하되
- 후에 자연어 질의를 위한 데이터 전처리 작업을 진행하는 것으로 기획했습니다.
- 또한 로그데이터를 전처리하는데에 있어 의미적인 내용의 생성 뿐 만 아니라, LLM 이 특정 형식의 문자열을 리턴할 수 있도록 구성해야 한다고 생각했습니다. 원본의 데이터를 올바른 형식으로 참고할 수 있으면 진실을 전달할 수 있어야 한다는 소기의 목적을 조금이라도 더 만족시킬 수 있기 떄문입니다.

> 공감이 갔던 내용: **"로그는 진실을 말해야 하며, 충분한 맥락과 구조, 그리고 책임(Accountability)을 담고 있어야 한다."**

---

## 🎯 핵심 원칙 (Core Principles)

이번 프로젝트에서 구현한 로깅 시스템 및 데이터 저장소는 다음과 같은 원칙 하에 구성했습니다.

- **와이드 이벤트 로깅 (Wide Event Logging)**
  - 하나의 요청(Request) → 하나의 컨텍스트가 풍부한 이벤트로 기록
- **설계 단계부터 고려된 구조화 및 고기수(High-Cardinality) 데이터**
  - 로그는 단순 기록이 아닌 '쿼리'를 위해 최적화됨
- **LLM은 '신뢰할 수 없는 엔티티'로 간주**
  - AI 활용 전후로 보안 및 권한 제어 적용
- **설계 기반 보안 및 프라이버시 (Security & Privacy by Design)**
  - 파이프라인의 첫 번째 단계부터 보안이 내재화됨
- **엔드투엔드 추적성 (End-to-End Traceability)**
  - AI가 생성한 모든 답변은 원본 소스까지 감사가 가능해야 함

---

## 🧭 프로젝트 로드맵 (Project Phases)

| 단계    | 설명                                                         | 상태 |
| :------ | :----------------------------------------------------------- | :--- |
| Phase 1 | NestJS 및 로컬 JSON 로그 기반의 맥락 기반 로깅 구축          | ✅   |
| Phase 2 | MongoDB를 활용한 로깅 / 쿼리 가능한 자산으로서의 로그 영속화 | ✅   |
| Phase 3 | 요약된 로그 이벤트의 RAG 기반 시맨틱 저장 (Vector DB)        | ✅   |
| Phase 4 | RAG 기반의 로그 검색 및 지능형 분석 시스템 구축              | ✅   |
| Phase 5 | 운영 안정화(Hardening): MQ, 캐싱, 샘플링 전략 적용           | ✅   |

---

## 🏗️ 아키텍처 철학 ("하드닝" 관점)

**Phase 5**에서 이 프로젝트는 기능 중심의 RAG 파이프라인을 넘어 **프로덕션 수준의 인프라**에 대해 이해하고자 구성했습니다.
핵심은 **기술적 통제권(Technical Control)**과 **회복 탄력성(Resilience)**입니다.

### 1. 수단으로서의 인프라 (Infrastructure as a Means)

- **격리를 위한 Kafka**:
  - Kafka는 로깅 오버헤드를 비즈니스 로직으로부터 **디커플링(Decouple)**하는 버퍼로 사용됩니다.
  - Phase 5에서 로깅시스템이 갑자기 중단되어도 재시작후 이전 로그데이터를 다룰 수 있도록 구현했습니다.
- **상태 관리를 위한 Redis**:
  - 분산 캐싱을 통해 애플리케이션을 **무상태(Stateless)**로 유지하고 수평 확장성을 확보하는 용도로 이해하고,
  - Phase 5에서 로깅 시스템 사용자의 조회 이력을 캐싱하는 용도로 구혔습니다.

### 2. 공학적 트레이드오프 (의도적 설계)

과도한 복잡성(Over-engineering)을 피하기 위해 다음 사항들을 의도적으로 선택했습니다:

- **자가 치유 버퍼 대신 서킷 브레이커**: 로그 재처리의 복잡한 상태 관리 대신, 예측 가능한 **서킷 브레이커(Circuit Breaker)**를 채택했습니다.
- **해시 기반 샘플링**: 복잡한 동적 정책 대신 해시 기반 샘플링을 사용하여 설명 가능하고 안정적인 로그 볼륨 제어를 구현했습니다.

### 3. 실험을 통한 검증 (Validation by Experiment)

단순 유닛 테스트를 넘어 **운영 시나리오(Operational Scenarios)**를 통한 시스템 검증을 진행했습니다:

- **감사 01 (Sampling)**:
  - 2,000건의 스트레스 테스트를 통해 에러 신호 유실 없이 80%의 비용 절감 증명.
  - Kafka 장애 시뮬레이션을 통해 DB 직접 저장(Direct-to-DB) 폴백 로직의 데이터 무손실 증명.
  - 인프라 재시작 시에도 세션 지속성 유지 확인.

---

## 🧱 기술 스택 (Tech Stack)

- **Backend**: NestJS, TypeScript
- **Observability**: Custom Wide Event Context (AsyncLocalStorage)
- **Storage**: Local (JSON), MongoDB (Time-series), Vector DB (Pinecone/Atlas)
- **AI / RAG**: LLM (Gemini flash 2.0 / VoyageAI) + Embeddings
- **Infra (Local)**: Docker Compose (MongoDB(atlas_local), kafka, zookeeper, redis)
- **Tooling**: Cursor, pnpm

---

## 🧠 프로젝트의 지향점 (What This Project Is and Is Not)

✅ **이 프로젝트는:**

- 관측 가능성(Observability), 로깅, 그리고 AI 신뢰성에 대해 탐구했습니다.
- 시스템 디자인 중심의 포트폴리오 프로젝트입니다.
- 아키텍처적 사고와 공학적 결정을 경험을 바탕으로 남기고자 했습니다.

❌ **이 프로젝트는:**

- 즉시 사용 가능한 SaaS 제품이 아닙니다.
- UI/UX 중심의 애플리케이션이 아닙니다.
- 일반적인 CRUD 데모 프로젝트가 아닙니다.

---

## 📚 상세 문서

각 단계별 상세 설계 및 구현 노트는 `/docs` 디렉토리를 참조해주세요!

---

## ⚠️ 면책 조항

- 이 프로젝트는 확장성이나 UI의 완결성보다 **아키텍처, 보안, 그리고 옵저버빌리티의 원칙**을 우선시하여 설계되었습니다.
- 성능 최적화 등의 부가적인 주제는 `/docs`의 Phase 6 문서에 업데이트 하고 있습니다.

---
